{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Long Short Term Memory - Pelengkap Harakat Huruf Hijaiyah.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, TimeDistributed, Bidirectional\n",
        "\n",
        "ribasti = pd.read_csv('RNN.csv')\n",
        "\n",
        "buckArab = {\"'\":\"ء\", \"|\":\"آ\", \"?\":\"أ\", \"&\":\"ؤ\", \"<\":\"إ\", \"}\":\"ئ\", \"A\":\"ا\", \"b\":\"ب\", \"p\":\"ة\", \"t\":\"ت\", \"v\":\"ث\", \"g\":\"ج\", \"H\":\"ح\", \"x\":\"خ\", \"d\":\"د\", \"*\":\"ذ\", \"r\":\"ر\", \"z\":\"ز\", \"s\":\"س\", \"$\":\"ش\", \"S\":\"ص\", \"D\":\"ض\", \"T\":\"ط\", \"Z\":\"ظ\", \"E\":\"ع\", \"G\":\"غ\", \"_\":\"ـ\", \"f\":\"ف\", \"q\":\"ق\", \"k\":\"ك\", \"l\":\"ل\", \"m\":\"م\", \"n\":\"ن\", \"h\":\"ه\", \"w\":\"و\", \"Y\":\"ى\", \"y\":\"ي\", \"F\":\"ً\", \"N\":\"ٌ\", \"K\":\"ٍ\", \"~\":\"ّ\", \"o\":\"ْ\", \"u\":\"ُ\", \"a\":\"َ\", \"i\":\"ِ\", \"{\":\"ا\"}\n",
        "\n",
        "def transString(string, reverse=0):\n",
        "    '''Given a Unicode string, transliterate into Buckwalter. To go from\n",
        "    Buckwalter back to Unicode, set reverse=1'''\n",
        "\n",
        "    for k, v in buckArab.items():\n",
        "        if not reverse:\n",
        "            string = string.replace(v, k)\n",
        "        else:\n",
        "            string = string.replace(k, v)\n",
        "\n",
        "    return string\n",
        "\n",
        "korpus = []\n",
        "for _ in ribasti['0']:\n",
        "  korpus.append(str(_))\n",
        "korpusan = \" \".join(korpus)\n",
        "\n",
        "korpus_harakat = []\n",
        "for _ in ribasti['1']:\n",
        "  korpus_harakat.append(str(_))\n",
        "korpusan_harakat = \" \".join(korpus_harakat)\n",
        "\n",
        "korpus2 = []\n",
        "korpusan2 = korpusan.split()\n",
        "for i in range(len(korpusan2)-7):\n",
        "  korpus2.append(\" \".join(korpusan2[i:i+7]))\n",
        "\n",
        "korpus2_h = []\n",
        "korpusan2_h = korpusan_harakat.split()\n",
        "for i in range(len(korpusan2_h)-7):\n",
        "  korpus2_h.append(\" \".join(korpusan2_h[i:i+7]))\n",
        "\n",
        "token_x = Tokenizer()\n",
        "token_y = Tokenizer()\n",
        "token_x.fit_on_texts(korpus2)\n",
        "token_y.fit_on_texts(korpus2_h)\n",
        "x_seq = token_x.texts_to_sequences(korpus2)\n",
        "y_seq = token_y.texts_to_sequences(korpus2_h)\n",
        "x_seq_padding = pad_sequences(x_seq, maxlen=7, padding=\"post\")\n",
        "x = np.asarray(x_seq_padding).astype(float)\n",
        "y_seq_padding = pad_sequences(y_seq, maxlen=7, padding=\"post\")\n",
        "y =  np.asarray(y_seq_padding)\n",
        "\n",
        "embedding_dim = 16\n",
        "classifier = Sequential()\n",
        "classifier.add(Embedding(int(np.max(x)+1), embedding_dim, input_length=x.shape[1], input_shape=x.shape[1:]))\n",
        "classifier.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "classifier.add(TimeDistributed(Dense(64, activation='relu')))\n",
        "classifier.add(TimeDistributed(Dense(int(np.max(y)+1), activation='softmax')))\n",
        "classifier.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "classifier.load_weights(\"ribasti.h5\")\n",
        "print(\"Masukan teks bahasa arab gundul : \")\n",
        "kalimat = input()\n",
        "kalimat_ = token_x.texts_to_sequences([kalimat])\n",
        "kalimat_pad = pad_sequences(kalimat_, maxlen=7, padding=\"post\")\n",
        "pred = classifier.predict(kalimat_pad)\n",
        "pred_ = [(np.argmax(pred[0][0])), (np.argmax(pred[0][1])), (np.argmax(pred[0][2])), (np.argmax(pred[0][3])), (np.argmax(pred[0][4])), (np.argmax(pred[0][5])), (np.argmax(pred[0][6]))]\n",
        "pred__ = []\n",
        "for i in pred_:\n",
        "  pred__.append([i])\n",
        "hasil_ = \" \".join(token_y.sequences_to_texts(pred__))\n",
        "kalimat__ = transString (kalimat, reverse=1)\n",
        "hasil__ = transString (hasil_, reverse=1)\n",
        "print(kalimat__)\n",
        "print(hasil_)\n",
        "print(hasil__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI-Snu24NOBP",
        "outputId": "42b20cbb-f82d-4c2d-8e61-8db943a92111"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masukan teks bahasa arab gundul : \n",
            "b sm {ll~h {l r~Hm`n {l r~Hym\n",
            "ب سم اللّه ال رّحم`ن ال رّحيم\n",
            "l r ahoma ni l r ahiymi\n",
            "ل ر َهْمَ نِ ل ر َهِيمِ\n"
          ]
        }
      ]
    }
  ]
}